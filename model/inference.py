import torch
import yaml
import os
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm

# Diffusers
from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler

# Custom Modules (ì‘ì„±í•˜ì‹  íŒŒì¼ë“¤ì´ ê°™ì€ ê²½ë¡œì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
from tokenizer import RadarPointNetPlusPlus
from KRadar_dataset import KRadarDataset
# utilsê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼ í™˜ê²½)
import utils.data_processing as dp


def load_config(config_path: str) -> dict:
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config


class RadarDiffusionInference:
    def __init__(self, checkpoint_path, config_path, device='cuda'):
        self.device = device
        self.config = load_config(config_path)
        
        print(f"ğŸš€ Loading models from {checkpoint_path}...")
        
        # 1. ëª¨ë¸ ì´ˆê¸°í™” (Pre-trained weights ë¶ˆëŸ¬ì˜¤ê¸°)
        model_id = "runwayml/stable-diffusion-v1-5"
        self.vae = AutoencoderKL.from_pretrained(model_id, subfolder="vae").to(self.device)
        self.unet = UNet2DConditionModel.from_pretrained(model_id, subfolder="unet").to(self.device)
        self.scheduler = DDPMScheduler.from_pretrained(model_id, subfolder="scheduler")
        
        # 2. Custom Radar Encoder ì´ˆê¸°í™”
        # í•™ìŠµ ì½”ë“œì˜ hidden_dimê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤ (ê¸°ë³¸ 768)
        self.radar_encoder = RadarPointNetPlusPlus(sd_hidden_dim=768).to(self.device)
        
        # 3. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # UNet ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.unet.load_state_dict(checkpoint['unet_state_dict'])
        # Radar Encoder ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.radar_encoder.load_state_dict(checkpoint['radar_encoder_state_dict'])
        
        # 4. Evaluation ëª¨ë“œ ì„¤ì •
        self.vae.eval()
        self.unet.eval()
        self.radar_encoder.eval()
        
        print("âœ… Models loaded successfully.")
    
    @torch.no_grad()
    def generate(self, radar_condition_tensor, num_inference_steps=50, guidance_scale=1.0):
        """
        radar_condition_tensor: (1, N, 4) í˜•íƒœì˜ í…ì„œ (Batch size 1 ê°€ì •)
        """
        # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • (Configì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’)
        height = self.config.get('dataset', {}).get('target_height', 384)
        width = self.config.get('dataset', {}).get('target_width', 680)
        
        # Latent í¬ê¸°ëŠ” ì´ë¯¸ì§€ì˜ 1/8
        latent_height = height // 8
        latent_width = width // 8
        
        batch_size = radar_condition_tensor.shape[0]
        
        # 1. Radar Encoding (Conditioning)
        radar_condition_tensor = radar_condition_tensor.to(self.device)
        # (B, N, 4) -> (B, 128, 768)
        encoder_hidden_states = self.radar_encoder(radar_condition_tensor)
        
        # 2. ì´ˆê¸° ë…¸ì´ì¦ˆ ìƒì„± (Latents)
        latents = torch.randn(
            (batch_size, self.unet.config.in_channels, latent_height, latent_width),
            device=self.device,
            dtype=torch.float32
        )
        
        # Scheduler ì´ˆê¸°í™”
        self.scheduler.set_timesteps(num_inference_steps)
        
        # 3. Denoising Loop
        print("ğŸ¨ Generating image...")
        for t in tqdm(self.scheduler.timesteps):
            # ëª¨ë¸ ì…ë ¥ ìŠ¤ì¼€ì¼ë§ (DDPMì€ ë³´í†µ ê·¸ëŒ€ë¡œì§€ë§Œ, ìŠ¤ì¼€ì¤„ëŸ¬ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            latent_model_input = latents
            
            # Noise ì˜ˆì¸¡
            # Unconditional guidance(CFG)ë¥¼ ì“´ë‹¤ë©´ ì—¬ê¸°ì„œ noise_pred_uncondë„ ê³„ì‚°í•´ì•¼ í•˜ì§€ë§Œ,
            # í˜„ì¬ ì½”ë“œëŠ” Radar Conditionë§Œ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ì´ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤.
            noise_pred = self.unet(
                latent_model_input,
                t,
                encoder_hidden_states=encoder_hidden_states
            ).sample
            
            # ì´ì „ ìŠ¤í…ì˜ Latent ê³„ì‚° (x_t -> x_t-1)
            latents = self.scheduler.step(noise_pred, t, latents).prev_sample
        
        # 4. Decoding (Latent -> Image)
        latents = 1 / 0.18215 * latents
        image = self.vae.decode(latents).sample
        
        # 5. Post-processing ([-1, 1] -> [0, 1] -> PIL)
        image = (image / 2 + 0.5).clamp(0, 1)
        image = image.cpu().permute(0, 2, 3, 1).numpy()
        
        if batch_size == 1:
            image = (image[0] * 255).astype(np.uint8)
            return Image.fromarray(image)
        else:
            images = (image * 255).astype(np.uint8)
            return [Image.fromarray(img) for img in images]


def preprocess_single_radar_file(npy_path, config):
    """
    KRadarDatasetì˜ __getitem__ ë¡œì§ì„ ì°¸ê³ í•˜ì—¬ ë‹¨ì¼ íŒŒì¼ ì „ì²˜ë¦¬
    (utils.data_processingì´ ìˆë‹¤ê³  ê°€ì •)
    """
    dataset_cfg = config['dataset']
    threshold = dataset_cfg['condition_threshold']
    max_points = dataset_cfg['max_points']
    
    polar_matrix = np.load(npy_path).astype(np.float32)
    
    # Polar -> Cartesian -> Voxelize
    cartesian_matrix = dp.polar_to_cartesian(polar_matrix, threshold=threshold, coord_normalize=True)
    voxel_points = dp.voxelize(cartesian_matrix, agg='max')
    num_points = voxel_points.shape[0]
    
    # Sampling logic (Datasetê³¼ ë™ì¼í•˜ê²Œ)
    if num_points == 0:
        raise Exception("ìœ íš¨í•œ í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    elif num_points >= max_points:
        choice_idx = np.random.choice(num_points, max_points, replace=False)
        fixed_points = voxel_points[choice_idx, :]
    else:
        choice_idx = np.random.choice(num_points, max_points, replace=True)
        fixed_points = voxel_points[choice_idx, :]
    
    tensor = torch.from_numpy(fixed_points).float()  # (max_points, 4)
    return tensor.unsqueeze(0)  # (1, max_points, 4) -> Batch ì°¨ì› ì¶”ê°€


def main():
    # ê²½ë¡œ ì„¤ì •
    config_path = r'C:\Users\jdmdj\Desktop\Diffusion_4DR\config\config.yaml'
    checkpoint_path = './checkpoints/checkpoint_epoch_10.pt'  # ì‚¬ìš©í•˜ë ¤ëŠ” ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
    
    # Inference ê°ì²´ ìƒì„±
    inferencer = RadarDiffusionInference(checkpoint_path, config_path)
    
    # í…ŒìŠ¤íŠ¸ ë°©ë²• 1: ë°ì´í„°ì…‹ì—ì„œ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ ì‰¬ìš´ ë°©ë²•)
    print("\nğŸ§ª Testing with a sample from KRadarDataset...")
    dataset = KRadarDataset(config_path)
    sample = dataset[0]  # ì²« ë²ˆì§¸ ë°ì´í„°
    
    radar_condition = sample['condition'].unsqueeze(0)  # (1, N, 4)
    ground_truth_img = dp.tensor_to_pil(sample['image'])  # (ê°€ì •) í™•ì¸ìš©
    
    # ì´ë¯¸ì§€ ìƒì„±
    generated_img = inferencer.generate(radar_condition, num_inference_steps=50)
    
    # ì €ì¥
    os.makedirs("results", exist_ok=True)
    generated_img.save("results/inference_result.png")
    print(f"ğŸ’¾ Generated image saved to results/inference_result.png")
    
    # ë§Œì•½ ì›ë³¸(Ground Truth)ê³¼ ë¹„êµí•˜ê³  ì‹¶ë‹¤ë©´ ì›ë³¸ë„ ì €ì¥
    # ground_truth_img.save("results/ground_truth.png")


if __name__ == "__main__":
    main()